{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 73 games out of 2463 total are missing data, and there are 58512 games with reviews\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/skipped_game_ids.txt\", \"r\") as f:\n",
    "    skipped = f.read().split(\",\")\n",
    "\n",
    "game_df = pd.read_csv(\"../data/game_info.csv\")\n",
    "review_df = pd.read_csv(\"../data/reviews.csv\")\n",
    "graph_df = pd.read_csv(\"../data/graph.csv\")\n",
    "games_to_add = [game_id for game_id in review_df['target_id'].value_counts().index if game_id not in game_df['id'].unique()]\n",
    "games_with_missing_data = game_df[game_df['long_description'].isna()]['id']\n",
    "games_with_missing_edges = [game_id for game_id in game_df['id'].unique() if game_id not in graph_df['game_id'].unique()]\n",
    "ids_to_scrape = [game_id for game_id in games_to_add if game_id not in skipped]\n",
    "REVIEW_DATA_PATH = \"../data/reviews.csv\"\n",
    "print(f\" {game_df['long_description'].isna().sum()} games out of {len(game_df)} total are missing data, and there are {len(games_to_add)} games with reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 127/200 [00:49<00:29,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 136/200 [00:58<00:30,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 141/200 [01:05<00:50,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 146/200 [01:12<00:49,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 155/200 [01:22<00:23,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [01:29<00:32,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 163/200 [01:36<00:50,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 166/200 [01:42<00:52,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 170/200 [01:49<00:37,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 174/200 [01:56<00:32,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 177/200 [02:03<00:34,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [02:09<00:31,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 183/200 [02:16<00:27,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 186/200 [02:22<00:22,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 189/200 [02:28<00:17,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 192/200 [02:35<00:12,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 195/200 [02:41<00:08,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 198/200 [02:48<00:03,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:54<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "edges = {}\n",
    "reviews = {}\n",
    "retries = 0\n",
    "\n",
    "for id in tqdm(ids_to_scrape[:200]): ## Only going to scrape the first 75 to make sure we aren't overloading BGG\n",
    "    id = int(id)\n",
    "    response = requests.get(f\"https://www.boardgamegeek.com/xmlapi2/thing?id={id}&stats=1&comments=1\")\n",
    "    # Convert the XML response to a dictionary\n",
    "    data_dict = xmltodict.parse(response.content)\n",
    "\n",
    "    temp_attributes = {}\n",
    "    mechanics = []\n",
    "    categories = []\n",
    "    families = []\n",
    "    designers = []\n",
    "    publishers = []\n",
    "    artists = []\n",
    "    if \"items\" not in data_dict:\n",
    "        if 'error' in data_dict:\n",
    "            if data_dict['error']['message']=='Rate limit exceeded.':\n",
    "                print(\"taking a break...\")\n",
    "                time.sleep(5)\n",
    "                if retries > 50:\n",
    "                    break\n",
    "                else:\n",
    "                    retries +=1 \n",
    "        continue\n",
    "    if 'item' not in data_dict['items']:\n",
    "        skipped.append(id)\n",
    "        continue\n",
    "    if data_dict['items']['item']['@type'] != 'boardgame':\n",
    "        skipped.append(id)\n",
    "        continue\n",
    "    num_ratings = data_dict['items']['item']['statistics']['ratings']['usersrated']['@value']\n",
    "    if int(num_ratings) < 500:\n",
    "        skipped.append(id)\n",
    "        continue\n",
    "    for item in data_dict['items']['item']['link']:\n",
    "        match item['@type']:\n",
    "            case \"boardgameartist\":\n",
    "                artists.append(item['@value'])\n",
    "            case \"boardgamecategory\":\n",
    "                categories.append(item['@value'])\n",
    "            case \"boardgamedesigner\":\n",
    "                designers.append(item['@value'])\n",
    "            case \"boardgamefamily\":\n",
    "                families.append(item['@value'])\n",
    "            case \"boardgamemechanic\":\n",
    "                mechanics.append(item['@value'])\n",
    "            case \"boardgamepublisher\":\n",
    "                publishers.append(item['@value'])\n",
    "    temp_attributes = {\"Mechanics\": mechanics, \"Categories\":categories, \"Families\": families, \"Designers\": designers, \"Publishers\": publishers, \"Artists\": artists}\n",
    "    edges[id]=temp_attributes\n",
    "\n",
    "    ## Append the new reviews to the review data\n",
    "    usernames= []\n",
    "    ratings = []\n",
    "    comments = []\n",
    "    if 'comments' in data_dict['items']['item']:\n",
    "        for comment in data_dict['items']['item']['comments']['comment']:\n",
    "            if comment['@rating'] == 'N/A':\n",
    "                continue\n",
    "            usernames.append(comment[\"@username\"])\n",
    "            ratings.append(comment['@rating'])\n",
    "            comments.append(comment['@value'])\n",
    "\n",
    "        include_header = not (os.path.isfile(REVIEW_DATA_PATH))\n",
    "        pd.DataFrame({\n",
    "            \"source_type\": \"Person\",\n",
    "            \"source_id\": usernames,\n",
    "            \"edge_type\": \"hasReviewed\",\n",
    "            \"target_type\": \"Game\",\n",
    "            \"target_id\": id,\n",
    "            \"rating\": ratings,\n",
    "            \"comment\": comments\n",
    "        }).to_csv(REVIEW_DATA_PATH, index=False, header=include_header, mode='a')\n",
    "\n",
    "    ## Fill in the missing data for the game info data\n",
    "    id = int(data_dict['items']['item']['@id'])     \n",
    "    image_url = data_dict['items']['item']['image']\n",
    "    long_description = data_dict['items']['item']['description']\n",
    "    year_published = int(data_dict['items']['item']['yearpublished']['@value'])\n",
    "    expected_play_time = int(data_dict['items']['item']['playingtime']['@value'])\n",
    "    min_play_time = int(data_dict['items']['item']['minplaytime'][\"@value\"])\n",
    "    max_play_time = int(data_dict['items']['item']['maxplaytime'][\"@value\"])\n",
    "    complexity_score = float(data_dict['items']['item']['statistics']['ratings']['averageweight']['@value'])\n",
    "    names = data_dict['items']['item']['name']\n",
    "    if type(names)==list:\n",
    "        name = [n['@value'] for n in names if n['@type']=='primary'][0]\n",
    "    else:\n",
    "        name = names['@value']\n",
    "\n",
    "    if int(id) in game_df['id'].values:\n",
    "        game_df.loc[game_df['id']==int(id), ['image_url','long_description','year_published','expected_play_time','min_play_time','max_play_time','complexity_socre']] = [image_url, long_description, year_published,expected_play_time,min_play_time,max_play_time,complexity_score]\n",
    "    else:\n",
    "        game_df = pd.concat([game_df, \n",
    "                   pd.DataFrame({\n",
    "                       \"id\": [int(id)],\n",
    "                       \"name\": [name],\n",
    "                       \"avg_rating\": [data_dict['items']['item']['statistics']['ratings']['average']['@value']],\n",
    "                       \"num_ratings\": [num_ratings],\n",
    "                       \"image_url\": [image_url],\n",
    "                       \"long_description\":[long_description],\n",
    "                       \"year_published\": [year_published],\n",
    "                       \"expected_play_time\":[expected_play_time],\n",
    "                       \"min_play_time\":[min_play_time],\n",
    "                       \"max_play_time\": [max_play_time],\n",
    "                       \"complexity_socre\": [complexity_score]\n",
    "                   })])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/skipped_game_ids.txt\", \"w\") as f:\n",
    "    f.write(\",\".join([str(id) for id in skipped]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now only 73 out of 2499 games have missing data\n",
      "Unique games: 2499\n"
     ]
    }
   ],
   "source": [
    "edge_df = pd.DataFrame(edges).T.rename(columns={\"Mechanics\":\"Mechanic\",\"Categories\":\"Category\",\"Families\":\"Family\",\"Artists\":\"Artist\",\"Designers\":\"Designer\", \"Publishers\":\"Company\"})\n",
    "graph_df = pd.read_csv(\"../data/graph.csv\")\n",
    "print(f\"Now only {game_df['long_description'].isna().sum()} out of {len(game_df)} games have missing data\\nUnique games: {len(game_df['id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.to_csv(\"../data/game_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeTypeMap = {\n",
    "    \"Mechanic\": \"hasMechanic\",\n",
    "    \"Category\": \"hasCategory\",\n",
    "    \"Company\": \"hasPublisher\",\n",
    "    \"Family\": \"hasFamily\",\n",
    "    \"Artist\": \"hasArtist\",\n",
    "    \"Designer\": \"hasDesigner\"\n",
    "}\n",
    "\n",
    "targetTypeMap = {'Mechanic':'Mechanic', \n",
    "                 'Category':'Category', \n",
    "                 'Family':'Family', \n",
    "                 'Designer':'Person', \n",
    "                 'Company':'Company', \n",
    "                 'Artist':'Person'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph = []\n",
    "for target_type, game_info in edge_df.to_dict().items():\n",
    "    for game_id, target_list in game_info.items():\n",
    "        for target in target_list:\n",
    "            temp = {\n",
    "                \"game_id\": game_id,\n",
    "                \"target\": target,\n",
    "                \"target_type\": targetTypeMap[target_type],\n",
    "                \"edge_type\": edgeTypeMap[target_type],\n",
    "                \"weight\": 1\n",
    "            }\n",
    "            new_graph.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 690 attribute edges to the graph\n"
     ]
    }
   ],
   "source": [
    "combined_graph_df = pd.concat([graph_df, pd.DataFrame(new_graph)]).drop_duplicates()\n",
    "combined_graph_df.to_csv(\"../data/graph.csv\", index=False)\n",
    "print(f\"Added {len(combined_graph_df) - len(graph_df)} attribute edges to the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2037 duplicate reviews\n"
     ]
    }
   ],
   "source": [
    "review_df = pd.read_csv(\"../data/reviews.csv\")\n",
    "filtered_reviews = review_df.drop_duplicates(subset=['source_id','target_id'], keep='last')\n",
    "filtered_reviews.to_csv(\"../data/reviews.csv\", index=False)\n",
    "print(f\"Removed {len(review_df) - len(filtered_reviews)} duplicate reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
