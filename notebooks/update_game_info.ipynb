{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58931 games are missing data\n"
     ]
    }
   ],
   "source": [
    "game_df = pd.read_csv(\"../data/game_info.csv\")\n",
    "review_df = pd.read_csv(\"../data/reviews.csv\")\n",
    "graph_df = pd.read_csv(\"../data/graph.csv\")\n",
    "games_to_add = [game_id for game_id in review_df['target_id'].unique() if game_id not in game_df['id'].unique()]\n",
    "games_with_missing_data = game_df[game_df['long_description'].isna()]['id']\n",
    "games_with_missing_edges = [game_id for game_id in game_df['id'].unique() if game_id not in graph_df['game_id'].unique()]\n",
    "ids_to_scrape = np.unique(list(games_with_missing_data) + games_with_missing_edges + list(games_to_add))\n",
    "REVIEW_DATA_PATH = \"../data/reviews.csv\"\n",
    "print(f\"{len(ids_to_scrape)} games are missing data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 66/75 [00:29<00:04,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 69/75 [00:36<00:07,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 72/75 [00:42<00:04,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking a break...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:49<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "edges = {}\n",
    "reviews = {}\n",
    "retries = 0\n",
    "for id in tqdm(ids_to_scrape[:75]): ## Only going to scrape the first 75 to make sure we aren't overloading BGG\n",
    "    response = requests.get(f\"https://www.boardgamegeek.com/xmlapi2/thing?id={id}&stats=1&comments=1\")\n",
    "    # Convert the XML response to a dictionary\n",
    "    data_dict = xmltodict.parse(response.content)\n",
    "\n",
    "    temp_attributes = {}\n",
    "    mechanics = []\n",
    "    categories = []\n",
    "    families = []\n",
    "    designers = []\n",
    "    publishers = []\n",
    "    artists = []\n",
    "    if \"items\" not in data_dict:\n",
    "        if 'error' in data_dict:\n",
    "            if data_dict['error']['message']=='Rate limit exceeded.':\n",
    "                print(\"taking a break...\")\n",
    "                time.sleep(5)\n",
    "                if retries > 2:\n",
    "                    break\n",
    "                else:\n",
    "                    retries +=1 \n",
    "        continue\n",
    "    if data_dict['items']['item']['@type'] != 'boardgame':\n",
    "        continue\n",
    "    num_ratings = data_dict['items']['item']['statistics']['ratings']['usersrated']['@value']\n",
    "    if int(num_ratings) < 500:\n",
    "        continue\n",
    "    for item in data_dict['items']['item']['link']:\n",
    "        match item['@type']:\n",
    "            case \"boardgameartist\":\n",
    "                artists.append(item['@value'])\n",
    "            case \"boardgamecategory\":\n",
    "                categories.append(item['@value'])\n",
    "            case \"boardgamedesigner\":\n",
    "                designers.append(item['@value'])\n",
    "            case \"boardgamefamily\":\n",
    "                families.append(item['@value'])\n",
    "            case \"boardgamemechanic\":\n",
    "                mechanics.append(item['@value'])\n",
    "            case \"boardgamepublisher\":\n",
    "                publishers.append(item['@value'])\n",
    "    temp_attributes = {\"Mechanics\": mechanics, \"Categories\":categories, \"Families\": families, \"Designers\": designers, \"Publishers\": publishers, \"Artists\": artists}\n",
    "    edges[id]=temp_attributes\n",
    "\n",
    "    ## Append the new reviews to the review data\n",
    "    usernames= []\n",
    "    ratings = []\n",
    "    comments = []\n",
    "    if 'comments' in data_dict['items']['item']:\n",
    "        for comment in data_dict['items']['item']['comments']['comment']:\n",
    "            if comment['@rating'] == 'N/A':\n",
    "                continue\n",
    "            usernames.append(comment[\"@username\"])\n",
    "            ratings.append(comment['@rating'])\n",
    "            comments.append(comment['@value'])\n",
    "\n",
    "        include_header = not (os.path.isfile(REVIEW_DATA_PATH))\n",
    "        pd.DataFrame({\n",
    "            \"source_type\": \"Person\",\n",
    "            \"source_id\": usernames,\n",
    "            \"edge_type\": \"hasReviewed\",\n",
    "            \"target_type\": \"Game\",\n",
    "            \"target_id\": id,\n",
    "            \"rating\": ratings,\n",
    "            \"comment\": comments\n",
    "        }).to_csv(REVIEW_DATA_PATH, index=False, header=include_header, mode='a')\n",
    "\n",
    "    ## Fill in the missing data for the game info data\n",
    "    id = int(data_dict['items']['item']['@id'])     \n",
    "    image_url = data_dict['items']['item']['image']\n",
    "    long_description = data_dict['items']['item']['description']\n",
    "    year_published = int(data_dict['items']['item']['yearpublished']['@value'])\n",
    "    expected_play_time = int(data_dict['items']['item']['playingtime']['@value'])\n",
    "    min_play_time = int(data_dict['items']['item']['minplaytime'][\"@value\"])\n",
    "    max_play_time = int(data_dict['items']['item']['maxplaytime'][\"@value\"])\n",
    "    complexity_score = float(data_dict['items']['item']['statistics']['ratings']['averageweight']['@value'])\n",
    "    names = data_dict['items']['item']['name']\n",
    "    if type(names)==list:\n",
    "        name = [n['@value'] for n in names if n['@type']=='primary'][0]\n",
    "    else:\n",
    "        name = names['@value']\n",
    "\n",
    "    if int(id) in game_df['id'].values:\n",
    "        game_df.loc[game_df['id']==int(id), ['image_url','long_description','year_published','expected_play_time','min_play_time','max_play_time','complexity_socre']] = [image_url, long_description, year_published,expected_play_time,min_play_time,max_play_time,complexity_score]\n",
    "    else:\n",
    "        game_df = pd.concat([game_df, \n",
    "                   pd.DataFrame({\n",
    "                       \"id\": [int(id)],\n",
    "                       \"name\": [name],\n",
    "                       \"avg_rating\": [data_dict['items']['item']['statistics']['ratings']['average']['@value']],\n",
    "                       \"num_ratings\": [num_ratings],\n",
    "                       \"image_url\": [image_url],\n",
    "                       \"long_description\":[long_description],\n",
    "                       \"year_published\": [year_published],\n",
    "                       \"expected_play_time\":[expected_play_time],\n",
    "                       \"min_play_time\":[min_play_time],\n",
    "                       \"max_play_time\": [max_play_time],\n",
    "                       \"complexity_socre\": [complexity_score]\n",
    "                   })])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now only 72 out of 2116 games have missing data\n",
      "Unique games: 2116\n"
     ]
    }
   ],
   "source": [
    "edge_df = pd.DataFrame(edges).T.rename(columns={\"Mechanics\":\"Mechanic\",\"Categories\":\"Category\",\"Families\":\"Family\",\"Artists\":\"Artist\",\"Designers\":\"Designer\", \"Publishers\":\"Company\"})\n",
    "graph_df = pd.read_csv(\"../data/graph.csv\")\n",
    "print(f\"Now only {game_df['long_description'].isna().sum()} out of {len(game_df)} games have missing data\\nUnique games: {len(game_df['id'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_df.to_csv(\"../data/game_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeTypeMap = {\n",
    "    \"Mechanic\": \"hasMechanic\",\n",
    "    \"Category\": \"hasCategory\",\n",
    "    \"Company\": \"hasPublisher\",\n",
    "    \"Family\": \"hasFamily\",\n",
    "    \"Artist\": \"hasArtist\",\n",
    "    \"Designer\": \"hasDesigner\"\n",
    "}\n",
    "\n",
    "targetTypeMap = {'Mechanic':'Mechanic', \n",
    "                 'Category':'Category', \n",
    "                 'Family':'Family', \n",
    "                 'Designer':'Person', \n",
    "                 'Company':'Company', \n",
    "                 'Artist':'Person'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph = []\n",
    "for target_type, game_info in edge_df.to_dict().items():\n",
    "    for game_id, target_list in game_info.items():\n",
    "        for target in target_list:\n",
    "            temp = {\n",
    "                \"game_id\": game_id,\n",
    "                \"target\": target,\n",
    "                \"target_type\": targetTypeMap[target_type],\n",
    "                \"edge_type\": edgeTypeMap[target_type],\n",
    "                \"weight\": 1\n",
    "            }\n",
    "            new_graph.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 299 attribute edges to the graph\n"
     ]
    }
   ],
   "source": [
    "combined_graph_df = pd.concat([graph_df, pd.DataFrame(new_graph)]).drop_duplicates()\n",
    "combined_graph_df.to_csv(\"../data/graph.csv\", index=False)\n",
    "print(f\"Added {len(combined_graph_df) - len(graph_df)} attribute edges to the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2346 duplicate reviews\n"
     ]
    }
   ],
   "source": [
    "review_df = pd.read_csv(\"../data/reviews.csv\")\n",
    "filtered_reviews = review_df.drop_duplicates(subset=['source_id','target_id'], keep='last')\n",
    "filtered_reviews.to_csv(\"../data/reviews.csv\", index=False)\n",
    "print(f\"Removed {len(review_df) - len(filtered_reviews)} duplicate reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
